{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68219a28-f05e-454c-9430-3079cb2310e7",
   "metadata": {},
   "source": [
    "# Projeto 03 - Previsão do Nível de Satisfação de Clientes do Santander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a91a4c8-e358-42db-87ab-23fb6cc25572",
   "metadata": {},
   "source": [
    "## Definindo o Problema de Negócio\n",
    "A satisfação do Cliente é uma medida fundamental de sucesso. Clientes insatisfeitos cancelam seus serviços e raramente expressam sua insatisfação antes de sair. Clientes satisfeitos, por outro lado, se tornam defensores da marca!\n",
    "\n",
    "O Banco Santander está pedindo para ajudá-los a identificar clientes insatisfeitos no início do relacionamento. Isso permitiria que o Santander adotasse medidas proativas para melhorar a experiência destes clientes antes que seja tarde demais.\n",
    "\n",
    "Neste projeto de aprendizado de máquina, vamos trabalhar com centenas de recursos anônimos para prever se um cliente está satisfeito ou insatisfeito com sua experiência bancária. O desafio é exatamente desconhecer a informação de cada variável e ao mesmo tempo termos uma quantidade enorme delas.\n",
    "\n",
    "Nosso objetivo é entregar  uma lista de clientes satisfeitos e insatisfeitos para o tomador de decisão, com uma acurácia de 70% em nosso modelo, buscando ter um modelo probabilístico mais simples e generalizável possível, facilitando assim para o tomador de decisão, utilizar seus resultados com boa clareza de entendimento. \n",
    "\n",
    "Utilizaremos a linguagem Python e um dataset disponível no Kaggle, pelo endereço:\n",
    "\n",
    "[https://www.kaggle.com/c/santander-customer-satisfaction](https://www.kaggle.com/c/santander-customer-satisfaction)\n",
    "    \n",
    "Note que os dados estão em 2 arquivos separados, train.csv e test.csv. Apenas o arquivo train.csv possui variável resposta, então vamos trabalhar durante o processo de construção do modelo preditivo somente com ele. Usaremos o arquivo test.csv para realizar as previsões do melhor modelo encontrado e entregar ao tomador de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b925c1-e40f-47d2-b920-aae977921d91",
   "metadata": {},
   "source": [
    "## Pacotes e Versões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be9ffe1-1399-4b6d-99fa-4b40096800d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy     : 1.23.5\n",
      "sklearn   : 1.0.2\n",
      "matplotlib: 3.6.2\n",
      "seaborn   : 0.12.2\n",
      "pandas    : 1.5.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = FutureWarning)\n",
    "\n",
    "# Versões dos Pacotes\n",
    "%reload_ext watermark\n",
    "%watermark --iversions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3470ba5-3ba4-4bdf-b2f6-25d70a6c4b6a",
   "metadata": {},
   "source": [
    "## Carregando os Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0fb079-a6eb-4265-a403-50b08578f277",
   "metadata": {},
   "source": [
    "Como explicamos na definição do problema, vamos trabalhar inicialmente somente com o arquivo train.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80a78a7-6b23-40d8-8bdb-aa1f4e603d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dados/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3062f9bd-e90d-4961-8f86-ba61ece4dc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1b3fde-6a9b-4e59-b60a-60de861f76da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32a178-ca22-4ed8-9970-d3de7bf289ad",
   "metadata": {},
   "source": [
    "## Limpeza e Análise Exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644fdd66-19ff-4c62-b9e4-ecfab460147b",
   "metadata": {},
   "source": [
    "Vamos verificar se há desequilibrio na variável TARGET..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "160276b9-6ee8-4a9b-a080-120087a7076d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73012\n",
       "1     3008\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d999a745-1a89-4721-af87-e2e4fbbb01e9",
   "metadata": {},
   "source": [
    "Temos uma variável resposta muito desequilibrada, o que pode tendenciar nosso modelo na previsão de apenas uma categoria. Vamos marcar aqui um ponto de revisão para nosso modelo.\n",
    "\n",
    "Olhando inicialmente para nossos dados, verificamos que possuimos um número imenso de variáveis sem descrição (370), ou seja, não temos como entender cada variável e analisar seus comportamentos, da forma que estão. Portanto inicialmente vamos verificar se temos dados faltantes (NaN), aplicando uma técnica para solucionar este problema. Logo depois vamos realizar 2 alternativas para uma redução de dimensionalidade, Seleção de Variáveis mais Importantes e Vetorização de Variáveis com PCA, para então criarmos os modelos e compará-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af374090-efa2-4f9a-ab41-c149ea4af429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                         0\n",
       "var3                       0\n",
       "var15                      0\n",
       "imp_ent_var16_ult1         0\n",
       "imp_op_var39_comer_ult1    0\n",
       "                          ..\n",
       "saldo_medio_var44_hace3    0\n",
       "saldo_medio_var44_ult1     0\n",
       "saldo_medio_var44_ult3     0\n",
       "var38                      0\n",
       "TARGET                     0\n",
       "Length: 371, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99844c8b-dd19-4c94-99d0-7e5be46bdfde",
   "metadata": {},
   "source": [
    "Não possuimos dados nulos, nem mesmo NaN em nosso dataset de trabalho. Vamos renomear as colunas para facilitar nossas visualizações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3298510-2dba-4df7-96af-5454d197fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewCols = []\n",
    "for i in range(0, 371):\n",
    "    col = \"Var\" + str(i)\n",
    "    NewCols.append(col)\n",
    "NewCols[0] = 'ID'\n",
    "NewCols[-1] = 'TARGET'\n",
    "OldCols = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e95a224b-37ec-4ebc-ad48-ee6cbfc3e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DePara = {}\n",
    "for i,j in zip(OldCols, NewCols):\n",
    "    DePara[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bef9b04-aada-4e17-a174-bbe373f0e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = DePara, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "404053b1-5e03-4c7a-aa6d-347024fc61e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Var1  Var2  Var3   Var4   Var5  Var6  Var7  Var8  Var9  ...  \\\n",
      "0           1     2    23   0.0    0.0    0.0   0.0   0.0   0.0   0.0  ...   \n",
      "1           3     2    34   0.0    0.0    0.0   0.0   0.0   0.0   0.0  ...   \n",
      "2           4     2    23   0.0    0.0    0.0   0.0   0.0   0.0   0.0  ...   \n",
      "3           8     2    37   0.0  195.0  195.0   0.0   0.0   0.0   0.0  ...   \n",
      "4          10     2    39   0.0    0.0    0.0   0.0   0.0   0.0   0.0  ...   \n",
      "...       ...   ...   ...   ...    ...    ...   ...   ...   ...   ...  ...   \n",
      "76015  151829     2    48   0.0    0.0    0.0   0.0   0.0   0.0   0.0  ...   \n",
      "76016  151830     2    39   0.0    0.0    0.0   0.0   0.0   0.0   0.0  ...   \n",
      "76017  151835     2    23   0.0    0.0    0.0   0.0   0.0   0.0   0.0  ...   \n",
      "76018  151836     2    25   0.0    0.0    0.0   0.0   0.0   0.0   0.0  ...   \n",
      "76019  151838     2    46   0.0    0.0    0.0   0.0   0.0   0.0   0.0  ...   \n",
      "\n",
      "       Var361  Var362  Var363  Var364  Var365  Var366  Var367  Var368  \\\n",
      "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "...       ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "76015     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "76016     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "76017     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "76018     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "76019     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "              Var369  TARGET  \n",
      "0       39205.170000       0  \n",
      "1       49278.030000       0  \n",
      "2       67333.770000       0  \n",
      "3       64007.970000       0  \n",
      "4      117310.979016       0  \n",
      "...              ...     ...  \n",
      "76015   60926.490000       0  \n",
      "76016  118634.520000       0  \n",
      "76017   74028.150000       0  \n",
      "76018   84278.160000       0  \n",
      "76019  117310.979016       0  \n",
      "\n",
      "[76020 rows x 371 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e825c617-7d74-4fca-a7a6-c27993aab4b6",
   "metadata": {},
   "source": [
    "Para continuar com nossos trabalhos, vamos eliminar a varável 'ID' em uma nova versão do nosso Dataset, pois a mesma não possui nenhum ganho de informação estatística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3c44fc2-8b79-4dfe-af8d-867daace10d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['ID'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "468e6182-5707-4da5-ade4-3a8d03d11fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Var1  Var2  Var3   Var4   Var5  Var6  Var7  Var8  Var9  Var10  ...  \\\n",
      "0         2    23   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
      "1         2    34   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
      "2         2    23   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
      "3         2    37   0.0  195.0  195.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
      "4         2    39   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
      "...     ...   ...   ...    ...    ...   ...   ...   ...   ...    ...  ...   \n",
      "76015     2    48   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
      "76016     2    39   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
      "76017     2    23   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
      "76018     2    25   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
      "76019     2    46   0.0    0.0    0.0   0.0   0.0   0.0   0.0    0.0  ...   \n",
      "\n",
      "       Var361  Var362  Var363  Var364  Var365  Var366  Var367  Var368  \\\n",
      "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "...       ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "76015     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "76016     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "76017     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "76018     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "76019     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "              Var369  TARGET  \n",
      "0       39205.170000       0  \n",
      "1       49278.030000       0  \n",
      "2       67333.770000       0  \n",
      "3       64007.970000       0  \n",
      "4      117310.979016       0  \n",
      "...              ...     ...  \n",
      "76015   60926.490000       0  \n",
      "76016  118634.520000       0  \n",
      "76017   74028.150000       0  \n",
      "76018   84278.160000       0  \n",
      "76019  117310.979016       0  \n",
      "\n",
      "[76020 rows x 370 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d33813-4ccb-4b5b-a220-1a4592b56997",
   "metadata": {},
   "source": [
    "Nosso Dataset está organizado e limpo, como temos um número muito grande de variáveis e não sabemos a informação que cada uma representa ao problema de negócio, fica inviável estudar a correlação de cada uma ou mesmo analisar as estatísticas centrais e de dispersão.\n",
    "Vamos trabalhar na redução de dimensionalidade para alcançar a melhor acurácia possível no nosso modelo preditivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee23e15-d2ae-4a78-8dda-5f91c5198b99",
   "metadata": {},
   "source": [
    "## Estratégia de Trabalho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6cacff-b88c-499b-b534-bd413b696b88",
   "metadata": {},
   "source": [
    "Como vimos temos alguns problemas aqui:\n",
    "\n",
    "    - Variáveis com Escalas Diferentes\n",
    "    - Variável TARGET desbalanceada\n",
    "    - Muitas variáveis, 369 para ser específico.\n",
    "\n",
    "Vamos criar 2 Cenários para este projeto:\n",
    "\n",
    "    - Cenário 1 -> Inicialmente vamos trabalhar com a variável TARGET, nossa variável resposta, desbalanceada e absorver este problema com o Algoritmo de Naive Bayes posteriormente. Vamos utilizar o Métodos de redução de dimensionalidade por Importância de Variáveis e Vetorização por PCA. Por fim Avaliamos as métricas e definimos o melhor modelo.\n",
    "    \n",
    "    - Cenário 2 -> Aplicamos uma técnica de imputação de dados a Variável TARGET, balanceando o Dataset. Usamos então as mesmas técnicas de redução de dimensionalidade do Cenário 1.\n",
    "    \n",
    "No final, comparamos qual o melhor modelo entre os cenários desenvolvidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db27a997-ed3a-4f62-a407-ad445baa36de",
   "metadata": {},
   "source": [
    "### Cenário 1 - Dataset Desbalanceado + Técnicas de Redução de Dimensionalidade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0fa265-c120-43e9-8e6a-0a251a33a737",
   "metadata": {},
   "source": [
    "Inicialmente vamos dividir os dados em Treino e Teste. Usaremos o pacote Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1221eb0a-456a-442a-8abb-8d976737960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtreino, Xteste, Ytreino, Yteste = train_test_split(df1.iloc[:, 0:369], df1.iloc[:, -1], test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35879692-bcb3-4cfd-8c94-43469ff8bd76",
   "metadata": {},
   "source": [
    "Separado os Datasets, vamos aplicar uma normalização nos dados de treino e teste para igualar as escalas das variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "15b70194-8f03-49c9-84b9-6250b9415ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(Xtreino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "662e6f2b-1c85-41dc-a560-5f85c66eefd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.99807940e-02, -7.89237455e-01, -5.24513963e-02, ...,\n",
       "        -1.91798836e-02, -2.00718862e-02, -4.84081375e-04],\n",
       "       [ 3.99807940e-02,  1.12995969e+00, -5.24513963e-02, ...,\n",
       "        -1.91798836e-02, -2.00718862e-02,  1.84784599e+00],\n",
       "       [ 3.99807940e-02,  5.15816600e-01, -5.24513963e-02, ...,\n",
       "        -1.91798836e-02, -2.00718862e-02, -4.20753830e-01],\n",
       "       ...,\n",
       "       [ 4.01560803e-02, -7.89237455e-01, -5.24513963e-02, ...,\n",
       "        -1.91798836e-02, -2.00718862e-02, -2.66835804e-01],\n",
       "       [ 3.99807940e-02, -2.51862256e-01, -1.50190114e-02, ...,\n",
       "        -1.91798836e-02, -2.00718862e-02, -2.81950539e-01],\n",
       "       [ 3.99807940e-02,  1.66733488e+00, -5.24513963e-02, ...,\n",
       "        -1.91798836e-02, -2.00718862e-02, -2.28898997e-01]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtreinoS = scaler.transform(Xtreino)\n",
    "XtreinoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2152e1ee-fddb-4a59-ad74-7bb4d303e647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.99807940e-02, -7.89237455e-01, -5.24513963e-02, ...,\n",
       "        -1.91798836e-02, -2.00718862e-02, -1.24801003e-01],\n",
       "       [ 3.99807940e-02, -7.89237455e-01, -5.24513963e-02, ...,\n",
       "        -1.91798836e-02, -2.00718862e-02,  1.36030923e-02],\n",
       "       [ 3.99807940e-02,  8.22888143e-01, -5.24513963e-02, ...,\n",
       "        -1.91798836e-02, -2.00718862e-02, -4.84081375e-04],\n",
       "       ...,\n",
       "       [ 3.99807940e-02, -7.89237455e-01, -5.24513963e-02, ...,\n",
       "        -1.91798836e-02, -2.00718862e-02,  2.12808818e-01],\n",
       "       [ 3.99807940e-02, -1.75094370e-01, -5.24513963e-02, ...,\n",
       "        -1.91798836e-02, -2.00718862e-02,  1.76104562e-01],\n",
       "       [ 3.99807940e-02, -7.89237455e-01, -5.24513963e-02, ...,\n",
       "        -1.91798836e-02, -2.00718862e-02, -4.15936973e-01]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtesteS = scaler.transform(Xteste)\n",
    "XtesteS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac74c3-55d4-40b8-b65a-1dc799336297",
   "metadata": {},
   "source": [
    "Datasets com escalas equivalentes, podemos aplicar nosso primeiro método de redução de dimensionalidade. Vamos aplicar um Feature Selection, baseado em um modelo de Regressão Logística, utilizando SelectFromModel do pacote sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d9bc9c55-2988-4be2-904d-17ab78208ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression('l2', random_state = 0, max_iter = 10000).fit(XtreinoS, Ytreino)\n",
    "model = SelectFromModel(LR, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "db3874a8-93c0-4cef-bae7-1fcd50590310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53214, 105)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtreino1 = model.transform(XtreinoS)\n",
    "Xtreino1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff44bc-3688-4967-8569-3087157d04b5",
   "metadata": {},
   "source": [
    "Chegamos a 105 variáveis importantes para a classificação de nossos Clientes, porém ainda temos muitas variáveis, sendo assim, vamos aplicar mais uma técnica para redução de dimensionalida, o PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e868785c-fa87-4f07-8f89-735ea62eb072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53214, 10)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtreino2 = PCA(n_components = 10).fit_transform(Xtreino1)\n",
    "Xtreino2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115145d2-6746-457a-8c91-9f5ecfe30215",
   "metadata": {},
   "source": [
    "Vamos trabalhar com 10 variáveis para este primeiro Modelo e avalir como performa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c16d2-79b0-460c-86cb-55c2d9e913bf",
   "metadata": {},
   "source": [
    "#### Modelo Base - Cenário 1 Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "71562a24-4305-4dfd-971d-9f0699b1483c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloBC01 = LogisticRegression(random_state=0, max_iter=10000).fit(Xtreino2, Ytreino)\n",
    "modeloBC01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab71642f-22b0-45d4-a9f0-d23ea7905a2a",
   "metadata": {},
   "source": [
    "Aplicando Redução de Dimensionalidade nos dados de Teste para fazermos as previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c7e5dc64-8d95-4761-84cb-6d5d50bd831e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22806, 10)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xteste1 = model.transform(XtesteS)\n",
    "Xteste2 = PCA(n_components = 10).fit_transform(Xteste1)\n",
    "Xteste2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd16247-e2d0-4ab1-b7a1-dfc6bd2bb5d7",
   "metadata": {},
   "source": [
    "Realizando as Previsões com o Modelo Treinado e Avaliando a performance deste modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7e56e8d6-4025-4f61-9fb9-dc5ccc732c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevBC01 = modeloBC01.predict(Xteste2)\n",
    "AccB01 = accuracy_score(Yteste, prevBC01)\n",
    "PrecB01 = precision_score(Yteste, prevBC01, average='weighted')\n",
    "AUCBC01 = roc_auc_score(Yteste, prevBC01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a52d5496-79c1-4912-b9bd-abdd3bc7200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Acurácia do Modelo Base C1 é  0.9528632815925634\n",
      "A Precisão do Modelo Base C1 é  0.9220152004196759\n",
      "A área sob a Curva ROC do Modelo Base C1 é  0.49789547734032313\n"
     ]
    }
   ],
   "source": [
    "print('A Acurácia do Modelo Base C1 é ', AccB01)\n",
    "print('A Precisão do Modelo Base C1 é ', PrecB01)\n",
    "print('A área sob a Curva ROC do Modelo Base C1 é ', AUCBC01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "79729c8e-1332-42a8-ba3e-c21e2b110680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Acurácia    0.952863\n",
       "Precisão    0.922015\n",
       "ROC AUC     0.497895\n",
       "dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLMC1 = pd.Series(data=[AccB01, PrecB01, AUCBC01], index=['Acurácia', 'Precisão', 'ROC AUC'])\n",
    "GLMC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f20c1007-3d73-4e70-abc1-65ff9d4a1564",
   "metadata": {},
   "outputs": [],
   "source": [
    "Resultado['GLMC1'] = pd.DataFrame(GLMC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6b7ddc82-ce75-47f0-b41a-ed90bfc7789e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLMC1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acurácia</th>\n",
       "      <td>0.952863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precisão</th>\n",
       "      <td>0.922015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC AUC</th>\n",
       "      <td>0.497895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             GLMC1\n",
       "Acurácia  0.952863\n",
       "Precisão  0.922015\n",
       "ROC AUC   0.497895"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813d3ea-0181-47e6-99cf-737412ed9166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
